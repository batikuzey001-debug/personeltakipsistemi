# apps/api/app/api/routes_reports.py
from fastapi import APIRouter, Depends, Query, HTTPException
from sqlalchemy.orm import Session
from sqlalchemy import and_
from datetime import datetime, timedelta, timezone
from statistics import mean
from typing import Literal, Dict, List, Tuple, Set

from app.deps import get_db, RolesAllowed
from app.models.events import Event, RawMessage
from app.models.models import Employee

router = APIRouter(prefix="/reports", tags=["reports"])

# ---------- helpers ----------
def _parse_date(s: str | None):
    if not s:
        return None
    try:
        d = datetime.strptime(s, "%Y-%m-%d")
        return d.replace(tzinfo=timezone.utc)
    except Exception:
        raise HTTPException(status_code=400, detail="date must be YYYY-MM-DD")

def _sign_emoji(pct: float | None) -> str:
    if pct is None:
        return "‚ö™"
    if pct > 3:
        return "üî¥‚¨ÜÔ∏è"
    if pct < -3:
        return "üü¢‚¨áÔ∏è"
    return "‚ö™"  # ¬±3%

def _root_origin_ts(chat_id: int, start_msg_id: int, db: Session, cache: Dict[Tuple[int,int], datetime | None]) -> datetime | None:
    """
    Reply zincirini yukarƒ± takip ederek K√ñK origin zamanƒ±nƒ± d√∂nd√ºr√ºr.
    RawMessage.json i√ßindeki reply_to_message.message_id alanƒ± kullanƒ±lƒ±r.
    """
    current_id = start_msg_id
    visited = set()
    while True:
        key = (chat_id, current_id)
        if key in cache:
            return cache[key]
        if key in visited:
            cache[key] = None
            return None
        visited.add(key)

        raw: RawMessage | None = (
            db.query(RawMessage)
            .filter(RawMessage.chat_id == chat_id, RawMessage.msg_id == current_id)
            .first()
        )
        if not raw:
            cache[key] = None
            return None

        try:
            j = raw.json or {}
            rt = j.get("message") or j.get("edited_message") or j.get("channel_post") or j.get("edited_channel_post") or {}
            replied = rt.get("reply_to_message") or {}
            parent_id = replied.get("message_id")
        except Exception:
            parent_id = None

        if parent_id:
            current_id = int(parent_id)
            continue
        else:
            cache[(chat_id, start_msg_id)] = raw.ts
            return raw.ts

# ---------- BONUS: ki≈üi bazlƒ± kapanƒ±≈ü ve ilk yanƒ±t raporu (sn) ----------
@router.get(
    "/bonus/close-time",
    dependencies=[Depends(RolesAllowed("super_admin","admin","manager"))],
)
def bonus_close_time(
    frm: str | None = Query(None, description="YYYY-MM-DD (default: son 7 g√ºn)"),
    to: str | None = Query(None, description="YYYY-MM-DD (exclusive, default: bug√ºn+1)"),
    order: Literal["avg_asc","avg_desc","cnt_desc"] = Query("avg_asc"),
    limit: int = Query(100, ge=1, le=500),
    offset: int = Query(0, ge=0),
    db: Session = Depends(get_db),
):
    """
    BONUS departmanƒ± i√ßin (employees.department='Bonus') ki≈üi bazlƒ± rapor.
    - ƒ∞≈ülem Sayƒ±sƒ± = close tipleri adedi (reply_close/approve/reject)
    - √ò ƒ∞lk Yanƒ±t (sn) = ki≈üinin reply_first.ts ‚àí k√∂k origin.ts
    - √ò Sonu√ßlandƒ±rma (sn) = ki≈üinin close.ts ‚àí k√∂k origin.ts
    - Trend = ki≈üinin √ò Sonu√ßlandƒ±rma (se√ßilen aralƒ±k) vs **EKƒ∞P √ò Son 7 G√ºn**
    """
    # Se√ßilen aralƒ±k (ki≈üisel metrikler)
    dt_to = _parse_date(to) or (datetime.now(timezone.utc) + timedelta(days=1))
    dt_from = _parse_date(frm) or (dt_to - timedelta(days=7))

    # Trend i√ßin baz aralƒ±k (her zaman SON 7 G√úN)
    trend_to = datetime.now(timezone.utc) + timedelta(days=1)
    trend_from = trend_to - timedelta(days=7)

    # Bonus departmanƒ±ndaki personeller
    bonus_emp_rows = db.query(Employee.employee_id, Employee.full_name, Employee.department)\
                       .filter(Employee.department == "Bonus").all()
    bonus_emp_ids = {r[0] for r in bonus_emp_rows}
    emp_info = {r[0]: (r[1] or r[0], r[2] or "Bonus") for r in bonus_emp_rows}
    if not bonus_emp_ids:
        return []

    close_types = ("reply_close", "approve", "reject")

    # first ve close eventleri (se√ßili aralƒ±k)
    first_rows: List[Event] = (
        db.query(Event)
        .filter(
            Event.source_channel == "bonus",
            Event.type == "reply_first",
            Event.employee_id.isnot(None),
            Event.employee_id.in_(bonus_emp_ids),
            Event.ts >= dt_from,
            Event.ts < dt_to,
        )
        .order_by(Event.ts.asc())
        .all()
    )
    close_rows: List[Event] = (
        db.query(Event)
        .filter(
            Event.source_channel == "bonus",
            Event.type.in_(close_types),
            Event.employee_id.isnot(None),
            Event.employee_id.in_(bonus_emp_ids),
            Event.ts >= dt_from,
            Event.ts < dt_to,
        )
        .order_by(Event.ts.asc())
        .all()
    )
    if not first_rows and not close_rows:
        return []

    root_cache: Dict[Tuple[int,int], datetime | None] = {}
    per_emp_first_secs: Dict[str, List[float]] = {}
    per_emp_close_secs: Dict[str, List[float]] = {}

    # √ò ƒ∞lk Yanƒ±t
    for e in first_rows:
        root_ts = _root_origin_ts(e.chat_id, e.msg_id, db, root_cache)
        if not root_ts:
            continue
        sec = (e.ts - root_ts).total_seconds()
        if sec < 0:
            continue
        per_emp_first_secs.setdefault(e.employee_id, []).append(sec)

    # √ò Sonu√ßlandƒ±rma
    for e in close_rows:
        root_ts = _root_origin_ts(e.chat_id, e.msg_id, db, root_cache)
        if not root_ts:
            continue
        sec = (e.ts - root_ts).total_seconds()
        if sec < 0:
            continue
        per_emp_close_secs.setdefault(e.employee_id, []).append(sec)

    if not per_emp_close_secs:
        return []

    # ------- Ekip √ò SON 7 G√úN (trend i√ßin sabit baz) -------
    team_close_trend_rows: List[Event] = (
        db.query(Event)
        .filter(
            Event.source_channel == "bonus",
            Event.type.in_(close_types),
            Event.employee_id.isnot(None),
            Event.employee_id.in_(bonus_emp_ids),
            Event.ts >= trend_from,
            Event.ts < trend_to,
        )
        .all()
    )
    team_root_cache: Dict[Tuple[int,int], datetime | None] = {}
    team_secs: List[float] = []
    for e in team_close_trend_rows:
        rts = _root_origin_ts(e.chat_id, e.msg_id, db, team_root_cache)
        if not rts:
            continue
        sec = (e.ts - rts).total_seconds()
        if sec >= 0:
            team_secs.append(sec)
    team_avg_close_sec = mean(team_secs) if team_secs else None
    # -------------------------------------------------------

    # satƒ±rlar
    rows = []
    for emp_id, close_secs in per_emp_close_secs.items():
        full_name, dept = emp_info.get(emp_id, (emp_id, "Bonus"))
        avg_close_sec = mean(close_secs)
        first_secs = per_emp_first_secs.get(emp_id, [])
        avg_first_sec = mean(first_secs) if first_secs else None
        trend_pct = None
        if team_avg_close_sec and team_avg_close_sec > 0:
            trend_pct = round(((avg_close_sec - team_avg_close_sec) / team_avg_close_sec) * 100, 0)

        rows.append({
            "employee_id": emp_id,
            "full_name": full_name,
            "department": dept,
            "count_total": len(close_secs),
            "avg_first_sec": int(round(avg_first_sec)) if avg_first_sec is not None else None,
            "avg_close_sec": int(round(avg_close_sec)),
            "trend": {
                "emoji": _sign_emoji(trend_pct),
                "pct": trend_pct,
                "team_avg_close_sec": int(round(team_avg_close_sec)) if team_avg_close_sec else None,
            }
        })

    # sƒ±ralama
    if order == "avg_desc":
        rows.sort(key=lambda r: (r["avg_close_sec"],), reverse=True)
    elif order == "cnt_desc":
        rows.sort(key=lambda r: (r["count_total"], r["avg_close_sec"]), reverse=True)
    else:  # avg_asc default
        rows.sort(key=lambda r: (r["avg_close_sec"], -r["count_total"]))

    return rows[offset: offset + limit]


# ---------- FINANS: ki≈üi bazlƒ± kapanƒ±≈ü ve ilk yanƒ±t raporu (sn) ----------
@router.get(
    "/finance/close-time",
    dependencies=[Depends(RolesAllowed("super_admin","admin","manager"))],
)
def finance_close_time(
    frm: str | None = Query(None, description="YYYY-MM-DD (default: son 7 g√ºn)"),
    to: str | None = Query(None, description="YYYY-MM-DD (exclusive, default: bug√ºn+1)"),
    order: Literal["avg_asc","avg_desc","cnt_desc"] = Query("avg_asc"),
    limit: int = Query(100, ge=1, le=500),
    offset: int = Query(0, ge=0),
    db: Session = Depends(get_db),
):
    """
    FINANS departmanƒ± i√ßin (employees.department='Finans') ki≈üi bazlƒ± rapor.
    Bonus raporuyla aynƒ± ≈üema ve mantƒ±k; sadece channel/department farklƒ±.
    Fallback: Eƒüer 'Finans' departmanƒ±nda ki≈üi yoksa, se√ßilen aralƒ±ktaki finans kapanƒ±≈ülarƒ±nƒ± yapan
    employee_id'lere g√∂re liste olu≈üturulur.
    """
    # Se√ßilen aralƒ±k
    dt_to = _parse_date(to) or (datetime.now(timezone.utc) + timedelta(days=1))
    dt_from = _parse_date(frm) or (dt_to - timedelta(days=7))

    # Trend i√ßin sabit baz (son 7 g√ºn, baƒüƒ±msƒ±z)
    trend_to = datetime.now(timezone.utc) + timedelta(days=1)
    trend_from = trend_to - timedelta(days=7)

    close_types = ("reply_close", "approve", "reject")

    # Finans departmanƒ± √ßalƒ±≈üanlarƒ±
    fin_emp_rows = db.query(Employee.employee_id, Employee.full_name, Employee.department)\
                     .filter(Employee.department == "Finans").all()
    fin_emp_ids: Set[str] = {r[0] for r in fin_emp_rows}
    emp_info: Dict[str, Tuple[str, str]] = {r[0]: (r[1] or r[0], r[2] or "Finans") for r in fin_emp_rows}

    # Fallback: departmanda kimse yoksa, se√ßili aralƒ±kta finans kapanƒ±≈üƒ± yapanlardan topla
    if not fin_emp_ids:
        closer_ids = {
            e.employee_id
            for e in db.query(Event.employee_id)
                       .filter(
                           Event.source_channel == "finans",
                           Event.type.in_(close_types),
                           Event.employee_id.isnot(None),
                           Event.ts >= dt_from, Event.ts < dt_to,
                       )
                       .distinct()
                       .all()
            if e.employee_id
        }
        if not closer_ids:
            return []
        # Bu id'ler i√ßin isim/departman √ßek
        emps = db.query(Employee.employee_id, Employee.full_name, Employee.department)\
                 .filter(Employee.employee_id.in_(closer_ids)).all()
        fin_emp_ids = {e[0] for e in emps}
        emp_info.update({e[0]: (e[1] or e[0], e[2] or "Finans") for e in emps})

    # first ve close eventleri (se√ßili aralƒ±k)
    first_rows: List[Event] = (
        db.query(Event)
        .filter(
            Event.source_channel == "finans",
            Event.type == "reply_first",
            Event.employee_id.isnot(None),
            Event.employee_id.in_(fin_emp_ids),
            Event.ts >= dt_from,
            Event.ts < dt_to,
        )
        .order_by(Event.ts.asc())
        .all()
    )
    close_rows: List[Event] = (
        db.query(Event)
        .filter(
            Event.source_channel == "finans",
            Event.type.in_(close_types),
            Event.employee_id.isnot(None),
            Event.employee_id.in_(fin_emp_ids),
            Event.ts >= dt_from,
            Event.ts < dt_to,
        )
        .order_by(Event.ts.asc())
        .all()
    )
    if not first_rows and not close_rows:
        return []

    # k√∂k origin ts cache
    root_cache: Dict[Tuple[int,int], datetime | None] = {}

    # ki≈üi bazƒ±nda s√ºreler (sn)
    per_emp_first_secs: Dict[str, List[float]] = {}
    per_emp_close_secs: Dict[str, List[float]] = {}

    # √ò ƒ∞lk Yanƒ±t
    for e in first_rows:
        root_ts = _root_origin_ts(e.chat_id, e.msg_id, db, root_cache)
        if not root_ts:
            continue
        sec = (e.ts - root_ts).total_seconds()
        if sec < 0:
            continue
        per_emp_first_secs.setdefault(e.employee_id, []).append(sec)

    # √ò Sonu√ßlandƒ±rma
    for e in close_rows:
        root_ts = _root_origin_ts(e.chat_id, e.msg_id, db, root_cache)
        if not root_ts:
            continue
        sec = (e.ts - root_ts).total_seconds()
        if sec < 0:
            continue
        per_emp_close_secs.setdefault(e.employee_id, []).append(sec)

    if not per_emp_close_secs:
        return []

    # ------- Finans Ekip √ò SON 7 G√úN (trend i√ßin) -------
    team_close_trend_rows: List[Event] = (
        db.query(Event)
        .filter(
            Event.source_channel == "finans",
            Event.type.in_(close_types),
            Event.employee_id.isnot(None),
            # Trend hesabƒ±nda departman filtresi: sadece finans √ßalƒ±≈üanlarƒ±
            Event.employee_id.in_(fin_emp_ids),
            Event.ts >= trend_from,
            Event.ts < trend_to,
        )
        .all()
    )
    team_root_cache: Dict[Tuple[int,int], datetime | None] = {}
    team_secs: List[float] = []
    for e in team_close_trend_rows:
        rts = _root_origin_ts(e.chat_id, e.msg_id, db, team_root_cache)
        if not rts:
            continue
        sec = (e.ts - rts).total_seconds()
        if sec >= 0:
            team_secs.append(sec)
    team_avg_close_sec = mean(team_secs) if team_secs else None
    # ----------------------------------------------------

    # satƒ±rlar
    rows = []
    for emp_id, close_secs in per_emp_close_secs.items():
        full_name, dept = emp_info.get(emp_id, (emp_id, "Finans"))
        avg_close_sec = mean(close_secs)
        first_secs = per_emp_first_secs.get(emp_id, [])
        avg_first_sec = mean(first_secs) if first_secs else None
        trend_pct = None
        if team_avg_close_sec and team_avg_close_sec > 0:
            trend_pct = round(((avg_close_sec - team_avg_close_sec) / team_avg_close_sec) * 100, 0)

        rows.append({
            "employee_id": emp_id,
            "full_name": full_name,
            "department": dept,
            "count_total": len(close_secs),
            "avg_first_sec": int(round(avg_first_sec)) if avg_first_sec is not None else None,
            "avg_close_sec": int(round(avg_close_sec)),
            "trend": {
                "emoji": _sign_emoji(trend_pct),
                "pct": trend_pct,
                "team_avg_close_sec": int(round(team_avg_close_sec)) if team_avg_close_sec else None,
            }
        })

    # sƒ±ralama
    if order == "avg_desc":
        rows.sort(key=lambda r: (r["avg_close_sec"],), reverse=True)
    elif order == "cnt_desc":
        rows.sort(key=lambda r: (r["count_total"], r["avg_close_sec"]), reverse=True)
    else:  # avg_asc default
        rows.sort(key=lambda r: (r["avg_close_sec"], -r["count_total"]))

    return rows[offset: offset + limit]
