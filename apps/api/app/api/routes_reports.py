# apps/api/app/api/routes_reports.py
from fastapi import APIRouter, Depends, Query, HTTPException
from sqlalchemy.orm import Session
from sqlalchemy import and_
from datetime import datetime, timedelta, timezone
from statistics import mean
from typing import Literal, Dict, List, Tuple

from app.deps import get_db, RolesAllowed
from app.models.events import Event, RawMessage
from app.models.models import Employee

router = APIRouter(prefix="/reports", tags=["reports"])

# ---------- helpers ----------
def _parse_date(s: str | None):
    if not s:
        return None
    try:
        d = datetime.strptime(s, "%Y-%m-%d")
        return d.replace(tzinfo=timezone.utc)
    except Exception:
        raise HTTPException(status_code=400, detail="date must be YYYY-MM-DD")

def _sign_emoji(pct: float | None) -> str:
    if pct is None:
        return "âšª"
    if pct > 3:
        return "ğŸ”´â¬†ï¸"
    if pct < -3:
        return "ğŸŸ¢â¬‡ï¸"
    return "âšª"  # Â±3%

def _root_origin_ts(chat_id: int, start_msg_id: int, db: Session, cache: Dict[Tuple[int,int], datetime | None]) -> datetime | None:
    """
    Reply zincirini yukarÄ± takip ederek KÃ–K origin zamanÄ±nÄ± dÃ¶ndÃ¼rÃ¼r.
    RawMessage.json iÃ§indeki reply_to_message.message_id alanÄ± kullanÄ±lÄ±r.
    """
    current_id = start_msg_id
    visited = set()
    while True:
        key = (chat_id, current_id)
        if key in cache:
            return cache[key]
        if key in visited:
            cache[key] = None
            return None
        visited.add(key)

        raw: RawMessage | None = (
            db.query(RawMessage)
            .filter(RawMessage.chat_id == chat_id, RawMessage.msg_id == current_id)
            .first()
        )
        if not raw:
            cache[key] = None
            return None

        try:
            j = raw.json or {}
            rt = j.get("message") or j.get("edited_message") or j.get("channel_post") or j.get("edited_channel_post") or {}
            replied = rt.get("reply_to_message") or {}
            parent_id = replied.get("message_id")
        except Exception:
            parent_id = None

        if parent_id:
            current_id = int(parent_id)
            continue
        else:
            cache[(chat_id, start_msg_id)] = raw.ts
            return raw.ts

# ---------- BONUS: kiÅŸi bazlÄ± kapanÄ±ÅŸ ve ilk yanÄ±t raporu (sn) ----------
@router.get(
    "/bonus/close-time",
    dependencies=[Depends(RolesAllowed("super_admin","admin","manager"))],
)
def bonus_close_time(
    frm: str | None = Query(None, description="YYYY-MM-DD (default: son 7 gÃ¼n)"),
    to: str | None = Query(None, description="YYYY-MM-DD (exclusive, default: bugÃ¼n+1)"),
    order: Literal["avg_asc","avg_desc","cnt_desc"] = Query("avg_asc"),
    limit: int = Query(100, ge=1, le=500),
    offset: int = Query(0, ge=0),
    db: Session = Depends(get_db),
):
    """
    BONUS departmanÄ± iÃ§in (employees.department='Bonus') kiÅŸi bazlÄ± rapor.
    - Ä°ÅŸlem SayÄ±sÄ± = close tipleri adedi (reply_close/approve/reject)
    - Ã˜ Ä°lk YanÄ±t (sn) = kiÅŸinin reply_first.ts âˆ’ kÃ¶k origin.ts
    - Ã˜ SonuÃ§landÄ±rma (sn) = kiÅŸinin close.ts âˆ’ kÃ¶k origin.ts
    - Trend = kiÅŸinin Ã˜ SonuÃ§landÄ±rma (seÃ§ilen aralÄ±k) vs **EKÄ°P Ã˜ Son 7 GÃ¼n**
    """
    # SeÃ§ilen aralÄ±k (kiÅŸisel metrikler)
    dt_to = _parse_date(to) or (datetime.now(timezone.utc) + timedelta(days=1))
    dt_from = _parse_date(frm) or (dt_to - timedelta(days=7))

    # Trend iÃ§in baz aralÄ±k (her zaman SON 7 GÃœN)
    trend_to = datetime.now(timezone.utc) + timedelta(days=1)
    trend_from = trend_to - timedelta(days=7)

    # Bonus departmanÄ±ndaki personeller
    bonus_emp_rows = db.query(Employee.employee_id, Employee.full_name, Employee.department)\
                       .filter(Employee.department == "Bonus").all()
    bonus_emp_ids = {r[0] for r in bonus_emp_rows}
    emp_info = {r[0]: (r[1] or r[0], r[2] or "Bonus") for r in bonus_emp_rows}
    if not bonus_emp_ids:
        return []

    close_types = ("reply_close", "approve", "reject")

    # first ve close eventleri (seÃ§ili aralÄ±k)
    first_rows: List[Event] = (
        db.query(Event)
        .filter(
            Event.source_channel == "bonus",
            Event.type == "reply_first",
            Event.employee_id.isnot(None),
            Event.employee_id.in_(bonus_emp_ids),
            Event.ts >= dt_from,
            Event.ts < dt_to,
        )
        .order_by(Event.ts.asc())
        .all()
    )
    close_rows: List[Event] = (
        db.query(Event)
        .filter(
            Event.source_channel == "bonus",
            Event.type.in_(close_types),
            Event.employee_id.isnot(None),
            Event.employee_id.in_(bonus_emp_ids),
            Event.ts >= dt_from,
            Event.ts < dt_to,
        )
        .order_by(Event.ts.asc())
        .all()
    )
    if not first_rows and not close_rows:
        return []

    # kÃ¶k origin ts cache
    root_cache: Dict[Tuple[int,int], datetime | None] = {}

    # kiÅŸi bazÄ±nda sÃ¼reler (sn)
    per_emp_first_secs: Dict[str, List[float]] = {}
    per_emp_close_secs: Dict[str, List[float]] = {}

    # Ã˜ Ä°lk YanÄ±t: reply_first.ts - kÃ¶k origin.ts
    for e in first_rows:
        root_ts = _root_origin_ts(e.chat_id, e.msg_id, db, root_cache)
        if not root_ts:
            continue
        sec = (e.ts - root_ts).total_seconds()
        if sec < 0:
            continue
        per_emp_first_secs.setdefault(e.employee_id, []).append(sec)

    # Ã˜ SonuÃ§landÄ±rma: close.ts - kÃ¶k origin.ts
    for e in close_rows:
        root_ts = _root_origin_ts(e.chat_id, e.msg_id, db, root_cache)
        if not root_ts:
            continue
        sec = (e.ts - root_ts).total_seconds()
        if sec < 0:
            continue
        per_emp_close_secs.setdefault(e.employee_id, []).append(sec)

    if not per_emp_close_secs:
        return []

    # ------- Ekip Ã˜ SON 7 GÃœN (trend iÃ§in sabit baz) -------
    team_close_trend_rows: List[Event] = (
        db.query(Event)
        .filter(
            Event.source_channel == "bonus",
            Event.type.in_(close_types),
            Event.employee_id.isnot(None),
            Event.employee_id.in_(bonus_emp_ids),
            Event.ts >= trend_from,
            Event.ts < trend_to,
        )
        .all()
    )
    team_root_cache: Dict[Tuple[int,int], datetime | None] = {}
    team_secs: List[float] = []
    for e in team_close_trend_rows:
        rts = _root_origin_ts(e.chat_id, e.msg_id, db, team_root_cache)
        if not rts:
            continue
        sec = (e.ts - rts).total_seconds()
        if sec >= 0:
            team_secs.append(sec)
    team_avg_close_sec = mean(team_secs) if team_secs else None
    # -------------------------------------------------------

    # satÄ±rlar
    rows = []
    for emp_id, close_secs in per_emp_close_secs.items():
        full_name, dept = emp_info.get(emp_id, (emp_id, "Bonus"))
        avg_close_sec = mean(close_secs)
        first_secs = per_emp_first_secs.get(emp_id, [])
        avg_first_sec = mean(first_secs) if first_secs else None
        trend_pct = None
        if team_avg_close_sec and team_avg_close_sec > 0:
            trend_pct = round(((avg_close_sec - team_avg_close_sec) / team_avg_close_sec) * 100, 0)

        rows.append({
            "employee_id": emp_id,
            "full_name": full_name,
            "department": dept,
            "count_total": len(close_secs),                              # Ä°ÅŸlem SayÄ±sÄ±
            "avg_first_sec": int(round(avg_first_sec)) if avg_first_sec is not None else None,  # sn (tam sayÄ±)
            "avg_close_sec": int(round(avg_close_sec)),                  # sn (tam sayÄ±)
            "trend": {
                "emoji": _sign_emoji(trend_pct),
                "pct": trend_pct,                                        # kiÅŸinin ort. sonuÃ§ vs EKÄ°P Ã˜ son 7 gÃ¼n
                "team_avg_close_sec": int(round(team_avg_close_sec)) if team_avg_close_sec else None,
            }
        })

    # sÄ±ralama
    if order == "avg_desc":
        rows.sort(key=lambda r: (r["avg_close_sec"],), reverse=True)
    elif order == "cnt_desc":
        rows.sort(key=lambda r: (r["count_total"], r["avg_close_sec"]), reverse=True)
    else:  # avg_asc default
        rows.sort(key=lambda r: (r["avg_close_sec"], -r["count_total"]))

    return rows[offset: offset + limit]
